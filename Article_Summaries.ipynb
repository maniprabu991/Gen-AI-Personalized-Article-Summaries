{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "tdKwceIXHwZg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve your API key securely from Colab environment variables (required for Gemini)\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "4sn6p5fGGOz2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(text, model_name=\"gemini-1.5-flash\", max_tokens=100, temperature=1):\n",
        "  \"\"\"\n",
        "  Summarizes a given text using the specified Gemini model.\n",
        "\n",
        "  Args:\n",
        "      text: The text to be summarized.\n",
        "      model_name: The name of the Gemini model to use (default: \"gemini-1.5-flash\").\n",
        "      max_tokens: Maximum number of tokens for the generated summary (default: 100).\n",
        "      temperature: Controls randomness of the generated text (default: 0.7).\n",
        "\n",
        "  Returns:\n",
        "      The generated summary of the provided text.\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize the GenerativeModel with the specified configuration\n",
        "  model = genai.GenerativeModel(\n",
        "      model_name,\n",
        "      generation_config=genai.GenerationConfig(\n",
        "          max_output_tokens=max_tokens,\n",
        "          temperature=temperature\n",
        "      )\n",
        "  )\n",
        "\n",
        "  # Craft a prompt that incorporates the text for summarization\n",
        "  prompt = f\"Summarize this text: \\n{text}\"\n",
        "\n",
        "  # Generate the summary using the model\n",
        "  response = model.generate_content(prompt)\n",
        "  return response.text.strip()"
      ],
      "metadata": {
        "id": "fDQOfaKIGW0V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "text = input('Enter News Article:')\n",
        "\n",
        "summary = summarize_text(text)\n",
        "print(\"Generated Summary:\")\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "4CU3w_lEGslO",
        "outputId": "5d20747a-2356-4a39-a6ab-0d2054c19cb2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter News Article:Biofuel production has reached record levels this year, driven by advancements in technology and increasing demand for sustainable fuel alternatives. Experts suggest that biofuels could play a crucial role in achieving carbon reduction goals and mitigating climate change impacts.\n",
            "Generated Summary:\n",
            "Biofuel production has hit record highs due to technological advancements and growing demand for sustainable alternatives. Experts believe biofuels are crucial for reducing carbon emissions and combating climate change.\n"
          ]
        }
      ]
    }
  ]
}